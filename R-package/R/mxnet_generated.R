######
# Generated by mxnet.export, do not edit by hand.
######

#' Take absolute value of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.abs
NULL

#' Take argmax indices of each channel of the src.The result will be ndarray of shape (num_channel,) on the same device.
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.argmax.channel
NULL

#' Take ceil value of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.ceil
NULL

#' Choose one element from each line(row for python, column for R/Julia) in lhs according to index indicated by rhs. This function assume rhs uses 0-based index.
#' 
#' @param lhs  NDArray
#'     Left operand to the function.
#' @param rhs  NDArray
#'     Right operand to the function.
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.choose.element.0index
NULL

#' Clip ndarray elements to range (a_min, a_max)
#' 
#' @param src  NDArray
#'     Source input
#' @param a.min  real_t
#'     Minimum value
#' @param a.max  real_t
#'     Maximum value
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.clip
NULL

#' Take cos of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.cos
NULL

#' Calculate dot product of two matrices or two vectors
#' 
#' @param lhs  NDArray
#'     Left operand  to the function
#' @param rhs  NDArray
#'     Right operand to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.dot
NULL

#' Take exp of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.exp
NULL

#' Fill one element of each line(row for python, column for R/Julia) in lhs according to index indicated by rhs and values indicated by mhs. This function assume rhs uses 0-based index.
#' 
#' @param lhs  NDArray
#'     Left operand to the function.
#' @param mhs  NDArray
#'     Middle operand to the function.
#' @param rhs  NDArray
#'     Right operand to the function.
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.fill.element.0index
NULL

#' Take floor value of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.floor
NULL

#' Take log of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.log
NULL

#' Take max of the src.The result will be ndarray of shape (1,) on the same device.
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.max
NULL

#' Take min of the src.The result will be ndarray of shape (1,) on the same device.
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.min
NULL

#' Take L2 norm of the src.The result will be ndarray of shape (1,) on the same device.
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.norm
NULL

#' Take round value of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.round
NULL

#' Take rsqrt of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.rsqrt
NULL

#' Take sign value of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.sign
NULL

#' Take sin of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.sin
NULL

#' Calculate cross_entropy(lhs, one_hot(rhs))
#' 
#' @param lhs  NDArray
#'     Left operand  to the function
#' @param rhs  NDArray
#'     Right operand to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.softmax.cross.entropy
NULL

#' Take sqrt of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.sqrt
NULL

#' Take square of the src
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.square
NULL

#' Take sum of the src.The result will be ndarray of shape (1,) on the same device.
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.sum
NULL

#' Take sum on medium dimension of the 3D src.
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.sum.mid.internal
NULL

#' Transpose the input matrix and return a new one
#' 
#' @param src  NDArray
#'     Source input to the function
#' @return out The result mx.ndarray
#' 
#' @export
#' @name mx.nd.transpose
NULL

#' Create iterator for dataset in csv.
#' 
#' @param data.csv  string, required
#'     Dataset Param: Data csv path.
#' @param data.shape  Shape(tuple), required
#'     Dataset Param: Shape of the data.
#' @param label.csv  string, optional, default='NULL'
#'     Dataset Param: Label csv path. If is NULL, all labels will be returned as 0
#' @param label.shape  Shape(tuple), optional, default=(1,)
#'     Dataset Param: Shape of the label.
#' @return iter The result mx.dataiter
#' 
#' @export
mx.io.CSVIter <- function(...) {
  mx.varg.io.CSVIter(list(...))
}

#' Create iterator for dataset packed in recordio.
#' 
#' @param path.imglist  string, optional, default=''
#'     Dataset Param: Path to image list.
#' @param path.imgrec  string, optional, default='./data/imgrec.rec'
#'     Dataset Param: Path to image record file.
#' @param aug.seq  string, optional, default='aug_default'
#'     Augmentation Param: the augmenter names to represent sequence of augmenters to be applied, seperated by comma. Additional keyword parameters will be seen by these augmenters.
#' @param label.width  int, optional, default='1'
#'     Dataset Param: How many labels for an image.
#' @param data.shape  Shape(tuple), required
#'     Dataset Param: Shape of each instance generated by the DataIter.
#' @param preprocess.threads  int, optional, default='4'
#'     Backend Param: Number of thread to do preprocessing.
#' @param verbose  boolean, optional, default=True
#'     Auxiliary Param: Whether to output parser information.
#' @param num.parts  int, optional, default='1'
#'     partition the data into multiple parts
#' @param part.index  int, optional, default='0'
#'     the index of the part will read
#' @param shuffle  boolean, optional, default=False
#'     Augmentation Param: Whether to shuffle data.
#' @param seed  int, optional, default='0'
#'     Augmentation Param: Random Seed.
#' @param batch.size  int (non-negative), required
#'     Batch Param: Batch size.
#' @param round.batch  boolean, optional, default=True
#'     Batch Param: Use round robin to handle overflow batch.
#' @param prefetch.buffer  , optional, default=4
#'     Backend Param: Number of prefetched parameters
#' @param rand.crop  boolean, optional, default=False
#'     Augmentation Param: Whether to random crop on the image
#' @param crop.y.start  int, optional, default='-1'
#'     Augmentation Param: Where to nonrandom crop on y.
#' @param crop.x.start  int, optional, default='-1'
#'     Augmentation Param: Where to nonrandom crop on x.
#' @param max.rotate.angle  int, optional, default='0'
#'     Augmentation Param: rotated randomly in [-max_rotate_angle, max_rotate_angle].
#' @param max.aspect.ratio  float, optional, default=0
#'     Augmentation Param: denotes the max ratio of random aspect ratio augmentation.
#' @param max.shear.ratio  float, optional, default=0
#'     Augmentation Param: denotes the max random shearing ratio.
#' @param max.crop.size  int, optional, default='-1'
#'     Augmentation Param: Maximum crop size.
#' @param min.crop.size  int, optional, default='-1'
#'     Augmentation Param: Minimum crop size.
#' @param max.random.scale  float, optional, default=1
#'     Augmentation Param: Maxmum scale ratio.
#' @param min.random.scale  float, optional, default=1
#'     Augmentation Param: Minimum scale ratio.
#' @param max.img.size  float, optional, default=1e+10
#'     Augmentation Param: Maxmum image size after resizing.
#' @param min.img.size  float, optional, default=0
#'     Augmentation Param: Minimum image size after resizing.
#' @param random.h  int, optional, default='0'
#'     Augmentation Param: Maximum value of H channel in HSL color space.
#' @param random.s  int, optional, default='0'
#'     Augmentation Param: Maximum value of S channel in HSL color space.
#' @param random.l  int, optional, default='0'
#'     Augmentation Param: Maximum value of L channel in HSL color space.
#' @param rotate  int, optional, default='-1'
#'     Augmentation Param: Rotate angle.
#' @param fill.value  int, optional, default='255'
#'     Augmentation Param: Maximum value of illumination variation.
#' @param data.shape  Shape(tuple), required
#'     Dataset Param: Shape of each instance generated by the DataIter.
#' @param inter.method  int, optional, default='1'
#'     Augmentation Param: 0-NN 1-bilinear 2-cubic 3-area 4-lanczos4 9-auto 10-rand.
#' @param mirror  boolean, optional, default=False
#'     Augmentation Param: Whether to mirror the image.
#' @param rand.mirror  boolean, optional, default=False
#'     Augmentation Param: Whether to mirror the image randomly.
#' @param mean.img  string, optional, default=''
#'     Augmentation Param: Mean Image to be subtracted.
#' @param mean.r  float, optional, default=0
#'     Augmentation Param: Mean value on R channel.
#' @param mean.g  float, optional, default=0
#'     Augmentation Param: Mean value on G channel.
#' @param mean.b  float, optional, default=0
#'     Augmentation Param: Mean value on B channel.
#' @param mean.a  float, optional, default=0
#'     Augmentation Param: Mean value on Alpha channel.
#' @param scale  float, optional, default=1
#'     Augmentation Param: Scale in color space.
#' @param max.random.contrast  float, optional, default=0
#'     Augmentation Param: Maximum ratio of contrast variation.
#' @param max.random.illumination  float, optional, default=0
#'     Augmentation Param: Maximum value of illumination variation.
#' @return iter The result mx.dataiter
#' 
#' @export
mx.io.ImageRecordIter <- function(...) {
  mx.varg.io.ImageRecordIter(list(...))
}

#' Create iterator for MNIST hand-written digit number recognition dataset.
#' 
#' @param image  string, optional, default='./train-images-idx3-ubyte'
#'     Dataset Param: Mnist image path.
#' @param label  string, optional, default='./train-labels-idx1-ubyte'
#'     Dataset Param: Mnist label path.
#' @param batch.size  int, optional, default='128'
#'     Batch Param: Batch Size.
#' @param shuffle  boolean, optional, default=True
#'     Augmentation Param: Whether to shuffle data.
#' @param flat  boolean, optional, default=False
#'     Augmentation Param: Whether to flat the data into 1D.
#' @param seed  int, optional, default='0'
#'     Augmentation Param: Random Seed.
#' @param silent  boolean, optional, default=False
#'     Auxiliary Param: Whether to print out data info.
#' @param num.parts  int, optional, default='1'
#'     partition the data into multiple parts
#' @param part.index  int, optional, default='0'
#'     the index of the part will read
#' @param prefetch.buffer  , optional, default=4
#'     Backend Param: Number of prefetched parameters
#' @return iter The result mx.dataiter
#' 
#' @export
mx.io.MNISTIter <- function(...) {
  mx.varg.io.MNISTIter(list(...))
}

#' Apply activation function to input.Softmax Activation is only available with CUDNN on GPUand will be computed at each location across channel if input is 4D.
#' 
#' @param data  Symbol
#'     Input data to activation function.
#' @param act.type  {'relu', 'sigmoid', 'softrelu', 'tanh'}, required
#'     Activation function to be applied.
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.Activation <- function(...) {
  mx.varg.symbol.Activation(list(...))
}

#' Apply batch normalization to input.
#' 
#' @param data  Symbol
#'     Input data to batch normalization
#' @param eps  float, optional, default=0.001
#'     Epsilon to prevent div 0
#' @param momentum  float, optional, default=0.9
#'     Momentum for moving average
#' @param fix.gamma  boolean, optional, default=True
#'     Fix gamma while training
#' @param use.global.stats  boolean, optional, default=False
#'     Whether use global moving statistics instead of local batch-norm. This will force change batch-norm into a scale shift operator.
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.BatchNorm <- function(...) {
  mx.varg.symbol.BatchNorm(list(...))
}

#' Get output from a symbol and pass 0 gradient back
#' 
#' @param data  Symbol
#'     Input data.
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.BlockGrad <- function(...) {
  mx.varg.symbol.BlockGrad(list(...))
}

#' Cast array to a different data type.
#' 
#' @param data  Symbol
#'     Input data to cast function.
#' @param dtype  {'float16', 'float32', 'float64', 'int32', 'uint8'}, required
#'     Target data type.
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.Cast <- function(...) {
  mx.varg.symbol.Cast(list(...))
}

#' Apply convolution to input then add a bias.
#' 
#' @param data  Symbol
#'     Input data to the ConvolutionOp.
#' @param weight  Symbol
#'     Weight matrix.
#' @param bias  Symbol
#'     Bias parameter.
#' @param kernel  Shape(tuple), required
#'     convolution kernel size: (y, x)
#' @param stride  Shape(tuple), optional, default=(1,1)
#'     convolution stride: (y, x)
#' @param dilate  Shape(tuple), optional, default=(1,1)
#'     convolution dilate: (y, x)
#' @param pad  Shape(tuple), optional, default=(0,0)
#'     pad for convolution: (y, x)
#' @param num.filter  int (non-negative), required
#'     convolution filter(channel) number
#' @param num.group  int (non-negative), optional, default=1
#'     Number of groups partition. This option is not supported by CuDNN, you can use SliceChannel to num_group,apply convolution and concat instead to achieve the same need.
#' @param workspace  long (non-negative), optional, default=512
#'     Tmp workspace for convolution (MB).
#' @param no.bias  boolean, optional, default=False
#'     Whether to disable bias parameter.
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.Convolution <- function(...) {
  mx.varg.symbol.Convolution(list(...))
}

#' Crop the 2nd and 3rd dim of input data, with the corresponding size of h_w or with width and height of the second input symbol, i.e., with one input, we need h_w to specify the crop height and width, otherwise the second input symbol's size will be used
#' 
#' @param data  Symbol or Symbol[]
#'     Tensor or List of Tensors, the second input will be used as crop_like shape reference
#' @param num.args  int, required
#'     Number of inputs for crop, if equals one, then we will use the h_wfor crop height and width, else if equals two, then we will use the heightand width of the second input symbol, we name crop_like here
#' @param offset  Shape(tuple), optional, default=(0,0)
#'     crop offset coordinate: (y, x)
#' @param h.w  Shape(tuple), optional, default=(0,0)
#'     crop height and weight: (h, w)
#' @param center.crop  boolean, optional, default=False
#'     If set to true, then it will use be the center_crop,or it will crop using the shape of crop_like
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.Crop <- function(...) {
  mx.varg.symbol.Crop(list(...))
}

#' Apply deconvolution to input then add a bias.
#' 
#' @param data  Symbol
#'     Input data to the DeconvolutionOp.
#' @param weight  Symbol
#'     Weight matrix.
#' @param bias  Symbol
#'     Bias parameter.
#' @param kernel  Shape(tuple), required
#'     deconvolution kernel size: (y, x)
#' @param stride  Shape(tuple), optional, default=(1,1)
#'     deconvolution stride: (y, x)
#' @param pad  Shape(tuple), optional, default=(0,0)
#'     pad for deconvolution: (y, x)
#' @param num.filter  int (non-negative), required
#'     deconvolution filter(channel) number
#' @param num.group  int (non-negative), optional, default=1
#'     number of groups partition
#' @param workspace  long (non-negative), optional, default=512
#'     Tmp workspace for deconvolution (MB)
#' @param no.bias  boolean, optional, default=True
#'     Whether to disable bias parameter.
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.Deconvolution <- function(...) {
  mx.varg.symbol.Deconvolution(list(...))
}

#' Apply dropout to input
#' 
#' @param data  Symbol
#'     Input data to dropout.
#' @param p  float, optional, default=0.5
#'     Fraction of the input that gets dropped out at training time
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.Dropout <- function(...) {
  mx.varg.symbol.Dropout(list(...))
}

#' Perform an elementwise sum over all the inputs.
#' 
#' @param num.args  int, required
#'     Number of inputs to be summed.
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.ElementWiseSum <- function(...) {
  mx.varg.symbol.ElementWiseSum(list(...))
}

#' Get embedding for one-hot input. A n-dimensional input tensor will be trainsformed into a (n+1)-dimensional tensor, where a new dimension is added for the embedding results.
#' 
#' @param data  Symbol
#'     Input data to the EmbeddingOp.
#' @param weight  Symbol
#'     Enbedding weight matrix.
#' @param input.dim  int, required
#'     input dim of one-hot encoding
#' @param output.dim  int, required
#'     output dim of embedding
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.Embedding <- function(...) {
  mx.varg.symbol.Embedding(list(...))
}

#' Flatten input
#' 
#' @param data  Symbol
#'     Input data to  flatten.
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.Flatten <- function(...) {
  mx.varg.symbol.Flatten(list(...))
}

#' Apply matrix multiplication to input then add a bias.
#' 
#' @param data  Symbol
#'     Input data to the FullyConnectedOp.
#' @param weight  Symbol
#'     Weight matrix.
#' @param bias  Symbol
#'     Bias parameter.
#' @param num.hidden  int, required
#'     Number of hidden nodes of the output.
#' @param no.bias  boolean, optional, default=False
#'     Whether to disable bias parameter.
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.FullyConnected <- function(...) {
  mx.varg.symbol.FullyConnected(list(...))
}

#' Apply a sparse regularization to the output a sigmoid activation function.
#' 
#' @param data  Symbol
#'     Input data.
#' @param sparseness.target  float, optional, default=0.1
#'     The sparseness target
#' @param penalty  float, optional, default=0.001
#'     The tradeoff parameter for the sparseness penalty
#' @param momentum  float, optional, default=0.9
#'     The momentum for running average
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.IdentityAttachKLSparseReg <- function(...) {
  mx.varg.symbol.IdentityAttachKLSparseReg(list(...))
}

#' Set the l2 norm of each instance to a constant.
#' 
#' @param data  Symbol
#'     Input data to the L2NormalizationOp.
#' @param eps  float, optional, default=1e-10
#'     Epsilon to prevent div 0
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.L2Normalization <- function(...) {
  mx.varg.symbol.L2Normalization(list(...))
}

#' Apply convolution to input then add a bias.
#' 
#' @param data  Symbol
#'     Input data to the ConvolutionOp.
#' @param alpha  float, optional, default=0.0001
#'     value of the alpha variance scaling parameter in the normalization formula
#' @param beta  float, optional, default=0.75
#'     value of the beta power parameter in the normalization formula
#' @param knorm  float, optional, default=2
#'     value of the k parameter in normalization formula
#' @param nsize  int (non-negative), required
#'     normalization window width in elements.
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.LRN <- function(...) {
  mx.varg.symbol.LRN(list(...))
}

#' Apply activation function to input.
#' 
#' @param data  Symbol
#'     Input data to activation function.
#' @param act.type  {'elu', 'leaky', 'prelu', 'rrelu'},optional, default='leaky'
#'     Activation function to be applied.
#' @param slope  float, optional, default=0.25
#'     Init slope for the activation. (For leaky and elu only)
#' @param lower.bound  float, optional, default=0.125
#'     Lower bound of random slope. (For rrelu only)
#' @param upper.bound  float, optional, default=0.334
#'     Upper bound of random slope. (For rrelu only)
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.LeakyReLU <- function(...) {
  mx.varg.symbol.LeakyReLU(list(...))
}

#' Use linear regression for final output, this is used on final output of a net.
#' 
#' @param data  Symbol
#'     Input data to function.
#' @param label  Symbol
#'     Input label to function.
#' @param grad.scale  float, optional, default=1
#'     Scale the gradient by a float factor
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.LinearRegressionOutput <- function(...) {
  mx.varg.symbol.LinearRegressionOutput(list(...))
}

#' Use Logistic regression for final output, this is used on final output of a net.
#' Logistic regression is suitable for binary classification or probability prediction tasks.
#' 
#' @param data  Symbol
#'     Input data to function.
#' @param label  Symbol
#'     Input label to function.
#' @param grad.scale  float, optional, default=1
#'     Scale the gradient by a float factor
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.LogisticRegressionOutput <- function(...) {
  mx.varg.symbol.LogisticRegressionOutput(list(...))
}

#' Use mean absolute error regression for final output, this is used on final output of a net.
#' 
#' @param data  Symbol
#'     Input data to function.
#' @param label  Symbol
#'     Input label to function.
#' @param grad.scale  float, optional, default=1
#'     Scale the gradient by a float factor
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.MAERegressionOutput <- function(...) {
  mx.varg.symbol.MAERegressionOutput(list(...))
}

#' Perform spatial pooling on inputs.
#' 
#' @param data  Symbol
#'     Input data to the pooling operator.
#' @param kernel  Shape(tuple), required
#'     pooling kernel size: (y, x)
#' @param pool.type  {'avg', 'max', 'sum'}, required
#'     Pooling type to be applied.
#' @param stride  Shape(tuple), optional, default=(1,1)
#'     stride: for pooling (y, x)
#' @param pad  Shape(tuple), optional, default=(0,0)
#'     pad for pooling: (y, x)
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.Pooling <- function(...) {
  mx.varg.symbol.Pooling(list(...))
}

#' Resize regions of interest in an input plane to a fixed size by MAX pooling.
#' 
#' @param data  Symbol[]
#'     [input tensor, regions of interest]
#' @param pooled.size  Shape(tuple), required
#'     target size: (h, w)
#' @param spatial.scale  float, required
#'     Ratio of input plane height (or w) to raw image height (or w).
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.ROIPooling <- function(...) {
  mx.varg.symbol.ROIPooling(list(...))
}

#' Reshape input to target shape
#' 
#' @param data  Symbol
#'     Input data to  reshape.
#' @param target.shape  Shape(tuple), required
#'     Target new shape. One and only one dim can be 0, in which case it will be inferred from the rest of dims
#' @param keep.highest  boolean, optional, default=False
#'     Whether keep the highest dim unchanged.If set to yes, than the first dim in target_shape is ignored,and always fixed as input
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.Reshape <- function(...) {
  mx.varg.symbol.Reshape(list(...))
}

#' Slice input equally along specified axis
#' 
#' @param num.outputs  int, required
#'     Number of outputs to be sliced.
#' @param axis  int, optional, default='1'
#'     Dimension along which to slice.
#' @param squeeze.axis  boolean, optional, default=False
#'     If true AND the sliced dimension becomes 1, squeeze that dimension.
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.SliceChannel <- function(...) {
  mx.varg.symbol.SliceChannel(list(...))
}

#' DEPRECATED: Perform a softmax transformation on input. Please use SoftmaxOutput
#' 
#' @param data  Symbol
#'     Input data to softmax.
#' @param grad.scale  float, optional, default=1
#'     Scale the gradient by a float factor
#' @param ignore.label  float, optional, default=-1
#'     the label value will be ignored during backward (only works if use_ignore is set to be true).
#' @param multi.output  boolean, optional, default=False
#'     If set to true, for a (n,k,x_1,..,x_n) dimensional input tensor, softmax will generate n*x_1*...*x_n output, each has k classes
#' @param use.ignore  boolean, optional, default=False
#'     If set to true, the ignore_label value will not contribute to the backward gradient
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.Softmax <- function(...) {
  mx.varg.symbol.Softmax(list(...))
}

#' Apply softmax activation to input. This is intended for internal layers. For output (loss layer) please use SoftmaxOutput. If type=instance, this operator will compute a softmax for each instance in the batch; this is the default mode. If type=channel, this operator will compute a num_channel-class softmax at each position of each instance; this can be used for fully convolutional network, image segmentation, etc.
#' 
#' @param data  Symbol
#'     Input data to activation function.
#' @param mode  {'channel', 'instance'},optional, default='instance'
#'     Softmax Mode. If set to instance, this operator will compute a softmax for each instance in the batch; this is the default mode. If set to channel, this operator will compute a num_channel-class softmax at each position of each instance; this can be used for fully convolutional network, image segmentation, etc.
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.SoftmaxActivation <- function(...) {
  mx.varg.symbol.SoftmaxActivation(list(...))
}

#' Perform a softmax transformation on input, backprop with logloss.
#' 
#' @param data  Symbol
#'     Input data to softmax.
#' @param label  Symbol
#'     Label data.
#' @param grad.scale  float, optional, default=1
#'     Scale the gradient by a float factor
#' @param ignore.label  float, optional, default=-1
#'     the label value will be ignored during backward (only works if use_ignore is set to be true).
#' @param multi.output  boolean, optional, default=False
#'     If set to true, for a (n,k,x_1,..,x_n) dimensional input tensor, softmax will generate n*x_1*...*x_n output, each has k classes
#' @param use.ignore  boolean, optional, default=False
#'     If set to true, the ignore_label value will not contribute to the backward gradient
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.SoftmaxOutput <- function(...) {
  mx.varg.symbol.SoftmaxOutput(list(...))
}

#' Apply swapaxis to input.
#' 
#' @param data  Symbol
#'     Input data to the SwapAxisOp.
#' @param dim1  int (non-negative), optional, default=0
#'     the first axis to be swapped.
#' @param dim2  int (non-negative), optional, default=0
#'     the second axis to be swapped.
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.SwapAxis <- function(...) {
  mx.varg.symbol.SwapAxis(list(...))
}

#' Perform nearest neighboor/bilinear up sampling to inputs
#' 
#' @param data  Symbol[]
#'     Array of tensors to upsample
#' @param scale  int (non-negative), required
#'     Up sampling scale
#' @param num.filter  int (non-negative), optional, default=0
#'     Input filter. Only used by nearest sample_type.
#' @param sample.type  {'bilinear', 'nearest'}, required
#'     upsampling method
#' @param multi.input.mode  {'concat', 'sum'},optional, default='concat'
#'     How to handle multiple input. concat means concatenate upsampled images along the channel dimension. sum means add all images together, only available for nearest neighbor upsampling.
#' @param num.args  int, required
#'     Number of inputs to be upsampled. For nearest neighbor upsampling, this can be 1-N; the size of output will be(scale*h_0,scale*w_0) and all other inputs will be upsampled to thesame size. For bilinear upsampling this must be 2; 1 input and 1 weight.
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.UpSampling <- function(...) {
  mx.varg.symbol.UpSampling(list(...))
}

#' Take absolute value of the src
#' 
#' @param lhs  Symbol
#'     Left symbolic input to the function
#' @param rhs  Symbol
#'     Left symbolic input to the function
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.abs <- function(...) {
  mx.varg.symbol.abs(list(...))
}

#' Take ceil value of the src
#' 
#' @param lhs  Symbol
#'     Left symbolic input to the function
#' @param rhs  Symbol
#'     Left symbolic input to the function
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.ceil <- function(...) {
  mx.varg.symbol.ceil(list(...))
}

#' Take cos of the src
#' 
#' @param lhs  Symbol
#'     Left symbolic input to the function
#' @param rhs  Symbol
#'     Left symbolic input to the function
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.cos <- function(...) {
  mx.varg.symbol.cos(list(...))
}

#' Calculate dot product of two matrices or two vectors
#' 
#' @param lhs  Symbol
#'     Left symbolic input to the function
#' @param rhs  Symbol
#'     Left symbolic input to the function
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.dot <- function(...) {
  mx.varg.symbol.dot(list(...))
}

#' Take exp of the src
#' 
#' @param lhs  Symbol
#'     Left symbolic input to the function
#' @param rhs  Symbol
#'     Left symbolic input to the function
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.exp <- function(...) {
  mx.varg.symbol.exp(list(...))
}

#' Take floor value of the src
#' 
#' @param lhs  Symbol
#'     Left symbolic input to the function
#' @param rhs  Symbol
#'     Left symbolic input to the function
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.floor <- function(...) {
  mx.varg.symbol.floor(list(...))
}

#' Take log of the src
#' 
#' @param lhs  Symbol
#'     Left symbolic input to the function
#' @param rhs  Symbol
#'     Left symbolic input to the function
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.log <- function(...) {
  mx.varg.symbol.log(list(...))
}

#' Take round value of the src
#' 
#' @param lhs  Symbol
#'     Left symbolic input to the function
#' @param rhs  Symbol
#'     Left symbolic input to the function
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.round <- function(...) {
  mx.varg.symbol.round(list(...))
}

#' Take rsqrt of the src
#' 
#' @param lhs  Symbol
#'     Left symbolic input to the function
#' @param rhs  Symbol
#'     Left symbolic input to the function
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.rsqrt <- function(...) {
  mx.varg.symbol.rsqrt(list(...))
}

#' Take sign value of the src
#' 
#' @param lhs  Symbol
#'     Left symbolic input to the function
#' @param rhs  Symbol
#'     Left symbolic input to the function
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.sign <- function(...) {
  mx.varg.symbol.sign(list(...))
}

#' Take sin of the src
#' 
#' @param lhs  Symbol
#'     Left symbolic input to the function
#' @param rhs  Symbol
#'     Left symbolic input to the function
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.sin <- function(...) {
  mx.varg.symbol.sin(list(...))
}

#' Calculate cross_entropy(lhs, one_hot(rhs))
#' 
#' @param lhs  Symbol
#'     Left symbolic input to the function
#' @param rhs  Symbol
#'     Left symbolic input to the function
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.softmax_cross_entropy <- function(...) {
  mx.varg.symbol.softmax_cross_entropy(list(...))
}

#' Take sqrt of the src
#' 
#' @param lhs  Symbol
#'     Left symbolic input to the function
#' @param rhs  Symbol
#'     Left symbolic input to the function
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.sqrt <- function(...) {
  mx.varg.symbol.sqrt(list(...))
}

#' Take square of the src
#' 
#' @param lhs  Symbol
#'     Left symbolic input to the function
#' @param rhs  Symbol
#'     Left symbolic input to the function
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.square <- function(...) {
  mx.varg.symbol.square(list(...))
}

#' Take sum of the src.The result will be ndarray of shape (1,) on the same device.
#' 
#' @param lhs  Symbol
#'     Left symbolic input to the function
#' @param rhs  Symbol
#'     Left symbolic input to the function
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.sum <- function(...) {
  mx.varg.symbol.sum(list(...))
}

#' Transpose the input matrix and return a new one
#' 
#' @param lhs  Symbol
#'     Left symbolic input to the function
#' @param rhs  Symbol
#'     Left symbolic input to the function
#' @param name  string, optional
#'     Name of the resulting symbol.
#' @return out The result mx.symbol
#' 
#' @export
mx.symbol.transpose <- function(...) {
  mx.varg.symbol.transpose(list(...))
}
