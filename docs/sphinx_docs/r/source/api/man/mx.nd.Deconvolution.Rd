% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mxnet_generated.R
\name{mx.nd.Deconvolution}
\alias{mx.nd.Deconvolution}
\title{Computes 1D or 2D transposed convolution (aka fractionally strided convolution) of the input tensor. This operation can be seen as the gradient of Convolution operation with respect to its input. Convolution usually reduces the size of the input. Transposed convolution works the other way, going from a smaller input to a larger output while preserving the connectivity pattern.}
\arguments{
\item{data}{NDArray-or-Symbol
Input tensor to the deconvolution operation.}

\item{weight}{NDArray-or-Symbol
Weights representing the kernel.}

\item{bias}{NDArray-or-Symbol
Bias added to the result after the deconvolution operation.}

\item{kernel}{Shape(tuple), required
Deconvolution kernel size: (w,), (h, w) or (d, h, w). This is same as the kernel size used for the corresponding convolution}

\item{stride}{Shape(tuple), optional, default=[]
The stride used for the corresponding convolution: (w,), (h, w) or (d, h, w). Defaults to 1 for each dimension.}

\item{dilate}{Shape(tuple), optional, default=[]
Dilation factor for each dimension of the input: (w,), (h, w) or (d, h, w). Defaults to 1 for each dimension.}

\item{pad}{Shape(tuple), optional, default=[]
The amount of implicit zero padding added during convolution for each dimension of the input: (w,), (h, w) or (d, h, w). ``(kernel-1)/2`` is usually a good choice. If `target_shape` is set, `pad` will be ignored and a padding that will generate the target shape will be used. Defaults to no padding.}

\item{adj}{Shape(tuple), optional, default=[]
Adjustment for output shape: (w,), (h, w) or (d, h, w). If `target_shape` is set, `adj` will be ignored and computed accordingly.}

\item{target.shape}{Shape(tuple), optional, default=[]
Shape of the output tensor: (w,), (h, w) or (d, h, w).}

\item{num.filter}{int (non-negative), required
Number of output filters.}

\item{num.group}{int (non-negative), optional, default=1
Number of groups partition.}

\item{workspace}{long (non-negative), optional, default=512
Maximum temporary workspace allowed (MB) in deconvolution.This parameter has two usages. When CUDNN is not used, it determines the effective batch size of the deconvolution kernel. When CUDNN is used, it controls the maximum temporary storage used for tuning the best CUDNN kernel when `limited_workspace` strategy is used.}

\item{no.bias}{boolean, optional, default=1
Whether to disable bias parameter.}

\item{cudnn.tune}{{None, 'fastest', 'limited_workspace', 'off'},optional, default='None'
Whether to pick convolution algorithm by running performance test.}

\item{cudnn.off}{boolean, optional, default=0
Turn off cudnn for this layer.}

\item{layout}{{None, 'NCDHW', 'NCHW', 'NCW', 'NDHWC', 'NHWC'},optional, default='None'
Set layout for input, output and weight. Empty for default layout, NCW for 1d, NCHW for 2d and NCDHW for 3d.NHWC and NDHWC are only supported on GPU.}
}
\value{
out The result mx.ndarray
}
\description{
Computes 1D or 2D transposed convolution (aka fractionally strided convolution) of the input tensor. This operation can be seen as the gradient of Convolution operation with respect to its input. Convolution usually reduces the size of the input. Transposed convolution works the other way, going from a smaller input to a larger output while preserving the connectivity pattern.
}

