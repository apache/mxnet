I"Å!<!--- Licensed to the Apache Software Foundation (ASF) under one -->
<!--- or more contributor license agreements.  See the NOTICE file -->
<!--- distributed with this work for additional information -->
<!--- regarding copyright ownership.  The ASF licenses this file -->
<!--- to you under the Apache License, Version 2.0 (the -->
<!--- "License"); you may not use this file except in compliance -->
<!--- with the License.  You may obtain a copy of the License at -->

<!---   http://www.apache.org/licenses/LICENSE-2.0 -->

<!--- Unless required by applicable law or agreed to in writing, -->
<!--- software distributed under the License is distributed on an -->
<!--- "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY -->
<!--- KIND, either express or implied.  See the License for the -->
<!--- specific language governing permissions and limitations -->
<!--- under the License. -->

<h1 id="basics">Basics</h1>

<p>This tutorial provides basic usages of the C++ package through the classical handwritten digits
identification database‚Äì<a href="http://yann.lecun.com/exdb/mnist/">MNIST</a>.</p>

<p>The following contents assume that the working directory is <code class="highlighter-rouge">/path/to/mxnet/cpp-package/example</code>.</p>

<h2 id="load-data">Load Data</h2>
<p>Before going into codes, we need to fetch MNIST data. You can either use the script <code class="highlighter-rouge">/path/to/mxnet/cpp-package/example/get_data.sh</code>,
or download mnist data by yourself from Lecun‚Äôs <a href="http://yann.lecun.com/exdb/mnist/">website</a>
and decompress them into <code class="highlighter-rouge">data/mnist_data</code> folder.</p>

<p>Except linking the MXNet shared library, the C++ package itself is a header-only package,
which means all you need to do is to include the header files. Among the header files,
<code class="highlighter-rouge">op.h</code> is special since it is generated dynamically. The generation should be done when
<a href="/api/cpp/">building the C++ package</a>.
It is important to note that you need to <strong>copy the shared library</strong> (<code class="highlighter-rouge">libmxnet.so</code> in Linux and MacOS,
<code class="highlighter-rouge">libmxnet.dll</code> in Windows) from <code class="highlighter-rouge">/path/to/mxnet/lib</code> to the working directory.
We do not recommend you to use pre-built binaries because MXNet is under heavy development,
the operator definitions in <code class="highlighter-rouge">op.h</code> may be incompatible with the pre-built version.</p>

<p>In order to use functionalities provides by the C++ package, first we include the general
header file <code class="highlighter-rouge">MxNetCpp.h</code> and specify the namespaces.</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include "mxnet-cpp/MxNetCpp.h"
</span>
<span class="k">using</span> <span class="k">namespace</span> <span class="n">std</span><span class="p">;</span>
<span class="k">using</span> <span class="k">namespace</span> <span class="n">mxnet</span><span class="o">::</span><span class="n">cpp</span><span class="p">;</span>
</code></pre></div></div>

<p>Next we can use the data iter to load MNIST data (separated to training sets and validation sets).
The digits in MNIST are 2-dimension arrays, so we should set <code class="highlighter-rouge">flat</code> to true to flatten the data.</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">auto</span> <span class="n">train_iter</span> <span class="o">=</span> <span class="n">MXDataIter</span><span class="p">(</span><span class="s">"MNISTIter"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">SetParam</span><span class="p">(</span><span class="s">"image"</span><span class="p">,</span> <span class="s">"./data/mnist_data/train-images-idx3-ubyte"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">SetParam</span><span class="p">(</span><span class="s">"label"</span><span class="p">,</span> <span class="s">"./data/mnist_data/train-labels-idx1-ubyte"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">SetParam</span><span class="p">(</span><span class="s">"batch_size"</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="p">.</span><span class="n">SetParam</span><span class="p">(</span><span class="s">"flat"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">.</span><span class="n">CreateDataIter</span><span class="p">();</span>
<span class="k">auto</span> <span class="n">val_iter</span> <span class="o">=</span> <span class="n">MXDataIter</span><span class="p">(</span><span class="s">"MNISTIter"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">SetParam</span><span class="p">(</span><span class="s">"image"</span><span class="p">,</span> <span class="s">"./data/mnist_data/t10k-images-idx3-ubyte"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">SetParam</span><span class="p">(</span><span class="s">"label"</span><span class="p">,</span> <span class="s">"./data/mnist_data/t10k-labels-idx1-ubyte"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">SetParam</span><span class="p">(</span><span class="s">"batch_size"</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="p">.</span><span class="n">SetParam</span><span class="p">(</span><span class="s">"flat"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">.</span><span class="n">CreateDataIter</span><span class="p">();</span>
</code></pre></div></div>

<p>The data have been successfully loaded. We can now easily construct various models to identify
the digits with the help of C++ package.</p>

<h2 id="gpu-support">GPU Support</h2>
<p>It‚Äôs worth noting that changing context from <code class="highlighter-rouge">Context::cpu()</code> to <code class="highlighter-rouge">Context::gpu()</code> is not enough,
because the data read by data iter are stored in memory, we cannot assign it directly to the
parameters. To bridge this gap, NDArray provides data synchronization functionalities between
GPU and CPU. We will illustrate it by making the mlp code run on GPU.</p>

<p>In the previous code, data are used like</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">args</span><span class="p">[</span><span class="s">"X"</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_batch</span><span class="p">.</span><span class="n">data</span><span class="p">;</span>
<span class="n">args</span><span class="p">[</span><span class="s">"label"</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_batch</span><span class="p">.</span><span class="n">label</span><span class="p">;</span>
</code></pre></div></div>

<p>It will be problematic if other parameters are created in the context of GPU. We can use
<code class="highlighter-rouge">NDArray::CopyTo</code> to solve this problem.</p>

<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Data provided by DataIter are stored in memory, should be copied to GPU first.</span>
<span class="n">data_batch</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">CopyTo</span><span class="p">(</span><span class="o">&amp;</span><span class="n">args</span><span class="p">[</span><span class="s">"X"</span><span class="p">]);</span>
<span class="n">data_batch</span><span class="p">.</span><span class="n">label</span><span class="p">.</span><span class="n">CopyTo</span><span class="p">(</span><span class="o">&amp;</span><span class="n">args</span><span class="p">[</span><span class="s">"label"</span><span class="p">]);</span>
<span class="c1">// CopyTo is imperative, need to wait for it to complete.</span>
<span class="n">NDArray</span><span class="o">::</span><span class="n">WaitAll</span><span class="p">();</span>
</code></pre></div></div>

<p>By replacing the former code to the latter one, we successfully port the code to GPU.
You can find the complete code in <code class="highlighter-rouge">mlp_gpu.cpp</code>. Compilation is similar to the cpu version.
Note that the shared library must be built with GPU support enabled.</p>
:ET